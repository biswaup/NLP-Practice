{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 3_Upa.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3MIUooLWVcLA","colab_type":"code","outputId":"a4e51c4c-84c9-466f-aeb9-5590b8a0a0a9","executionInfo":{"status":"ok","timestamp":1559116435679,"user_tz":-120,"elapsed":10121,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74}},"source":["# import file\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-82baaf7d-a380-45d3-af74-32c967157de0\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-82baaf7d-a380-45d3-af74-32c967157de0\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving yelp14_label.txt to yelp14_label.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VLEou74V-PEL","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import codecs\n","import operator\n","import numpy as np\n","import re\n","from time import time\n","from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Input, SpatialDropout1D\n","from keras.models import Model, Sequential\n","from keras.preprocessing import sequence\n","from keras.utils.np_utils import to_categorical\n","domain = 'yelp14'\n","data_path = './yelp14_text.txt'\n","text_path = './yelp14_text.txt'\n","score_path = './yelp14_label.txt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HjVRFnlJ-PAx","colab_type":"code","colab":{}},"source":["# create a vocabulary\n","def prepare_data(data_path, vocab_size, skip_top=0, skip_len=0, replace_non_vocab=1):\n","    \n","    # what is skip_len? never been used after initiating\n","    # get all words, find vocab_size number of top occuring words and make the dictionary with their indices\n","    vocab = create_vocab(data_path, skip_len, vocab_size)\n","\n","    # take each line and its corresponding label\n","    # take each word from the line and encode it according to the dictionary formed before\n","    # numbers and unknown words are indexed as stored in dictionary given below\n","    data, label, max_len = create_data(vocab, text_path, score_path, domain, skip_top, skip_len, replace_non_vocab)\n","\n","    return vocab, data, label, max_len"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4gQupdHk-O8Z","colab_type":"code","colab":{}},"source":["num_regex = re.compile('^[+-]?[0-9]+\\.?[0-9]*$')\n","\n","def create_vocab(data_path, maxlen=0, vocab_size=0):\n","    print(domain)\n","    print('Creating vocab ...')\n","    total_words, unique_words = 0, 0\n","    word_freqs = {}\n","\n","    fin = open(data_path)\n","    for line in fin:\n","        words = line.split()\n","        if maxlen > 0 and len(words) > maxlen:\n","            continue\n","\n","        for w in words:\n","            if not bool(num_regex.match(w)):\n","                try:\n","                    word_freqs[w] += 1\n","                except KeyError:\n","                    unique_words += 1\n","                    word_freqs[w] = 1\n","                total_words += 1\n","\n","    print ('  %i total words, %i unique words' % (total_words, unique_words))\n","    sorted_word_freqs = sorted(word_freqs.items(), key=operator.itemgetter(1), reverse=True)\n","\n","    vocab = {'<pad>':0, '<unk>':1, '<num>':2}\n","    index = len(vocab)\n","    for word, _ in sorted_word_freqs:\n","        vocab[word] = index\n","        index += 1\n","        if vocab_size > 0 and index > vocab_size + 2:\n","            break\n","    if vocab_size > 0:\n","        print (' keep the top %i words' % vocab_size)\n","\n","  \n","    return vocab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ydMkcZVJ-O-h","colab_type":"code","colab":{}},"source":["def create_data(vocab, text_path, label_path, domain, skip_top, skip_len, replace_non_vocab):\n","    \n","    data = []\n","    label = [] # {pos: 0, neg: 1, neu: 2}\n","    \n","    f = codecs.open(text_path, 'r', 'utf-8')\n","    f_l = codecs.open(label_path, 'r', 'utf-8')\n","    \n","    num_hit, unk_hit, skip_top_hit, total = 0., 0., 0., 0.\n","    pos_count, neg_count, neu_count = 0, 0, 0\n","    max_len = 0\n","    \n","    for line, score in zip(f, f_l):\n","        \n","        word_indices = []\n","        words = line.split()\n","\n","        if skip_len > 0 and len(words) > skip_len:\n","            continue\n","\n","        score = float(score.strip())\n","        if score < 3:\n","            neg_count += 1\n","            label.append(1)\n","        elif score > 3:\n","            pos_count += 1\n","            label.append(0)\n","        else:\n","            neu_count += 1\n","            label.append(2)\n","          \n","        for word in words:\n","            if bool(num_regex.match(word)):\n","                word_indices.append(vocab['<num>'])\n","                num_hit += 1\n","            elif word in vocab:\n","                word_ind = vocab[word]\n","                if skip_top > 0 and word_ind < skip_top + 3:\n","                    skip_top_hit += 1\n","                else:\n","                    word_indices.append(word_ind)\n","            else:\n","                if replace_non_vocab:\n","                    word_indices.append(vocab['<unk>'])\n","                unk_hit += 1\n","            total += 1\n","\n","        if len(word_indices) > max_len:\n","            max_len = len(word_indices)\n","\n","        data.append(word_indices)\n","\n","    f.close()\n","    f_l.close()\n","\n","    print('  <num> hit rate: %.2f%%, <unk> hit rate: %.2f%%' % (100*num_hit/total, 100*unk_hit/total))\n","    print( 'pos count: ', pos_count )\n","    print( 'neg count: ', neg_count )\n","    print( 'neu count: ', neu_count )\n","\n","    return np.array(data), np.array(label), max_len"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"psKIPA4myi9d","colab_type":"code","outputId":"a96a479c-a9f3-45ae-eccc-472cacf3e8ba","executionInfo":{"status":"ok","timestamp":1559116467867,"user_tz":-120,"elapsed":7563,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["# start of the data preprocess\n","vocab, data_list, label_list, overall_maxlen = prepare_data(data_path, 10000)\n","print(overall_maxlen)\n","words_idx = vocab\n","idx_words = dict((v,k) for (k,v) in vocab.items())\n","\n","print('printing word-index VS index-word')\n","print(list(idx_words.items())[:5])\n","print(list(vocab.items())[:5])\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["yelp14\n","Creating vocab ...\n","  3829257 total words, 43607 unique words\n"," keep the top 10000 words\n","  <num> hit rate: 0.87%, <unk> hit rate: 2.05%\n","pos count:  10000\n","neg count:  10000\n","neu count:  10000\n","1008\n","printing word-index VS index-word\n","[(0, '<pad>'), (1, '<unk>'), (2, '<num>'), (3, 'the'), (4, 'and')]\n","[('<pad>', 0), ('<unk>', 1), ('<num>', 2), ('the', 3), ('and', 4)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a7DEo7NWezUS","colab_type":"code","outputId":"8207ec78-79e5-4cd6-fbb4-d8d361067a69","executionInfo":{"status":"ok","timestamp":1559116470971,"user_tz":-120,"elapsed":1668,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}},"colab":{"base_uri":"https://localhost:8080/","height":356}},"source":["# len(data_list) = 30000\n","data_size = len(data_list)\n","\n","# print before shuffling\n","print('print BEFORE shuffling and categorizing the label values')\n","print(data_list[25])\n","print(label_list[25])\n","\n","# Return evenly spaced values within a given interval.\n","rand_idx = np.arange(len(data_list))\n","# print(rand_idx)\n","np.random.shuffle(rand_idx)\n","# print(rand_idx)\n","\n","# shuffle data with corresponding labels\n","data = data_list[rand_idx]\n","label_ = label_list[rand_idx]\n","label = to_categorical(label_)\n","\n","print('\\nprint AFTER shuffling and categorizing the label values')\n","print(data[25])\n","print('Label before categorizing: ', label_[25])\n","print(label[25][0], label[25][1], label[25][2])\n","\n","print(data[590])\n","print('Label before categorizing: ', label_[590])\n","print(label[590][0], label[590][1], label[590][2])\n","\n","# create train, validation and test set\n","test_x = data[0:1000]\n","test_y = label[0:1000]\n","\n","dev_x = data[1000:5000]\n","dev_y = label[1000:5000]\n","\n","train_x = data[5000:int(data_size)]\n","train_y = label[5000:int(data_size)]\n","\n","print('\\nprinting shape of train data')\n","print(train_x.shape, train_y.shape)\n","\n","# make each instance of training data equal length by padding (why max length from the dev set??????)\n","mLength = np.max([len(d) for d in dev_x])\n","train_x_ = sequence.pad_sequences(train_x, mLength)\n","dev_x_ = sequence.pad_sequences(dev_x, mLength)\n","test_x_ = sequence.pad_sequences(test_x, mLength)\n","print('\\nprinting after padding sequences')\n","print(mLength)\n","\n","# convert to numpy arrays\n","train_x_ = np.array(train_x_)\n","train_y = np.array(train_y)\n","\n","dev_x_ = np.array(dev_x_)\n","dev_y = np.array(dev_y)\n","\n","test_x_ = np.array(test_x_)\n","test_y = np.array(test_y)\n","print(train_x_.shape)\n","print(train_y.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["print BEFORE shuffling and categorizing the label values\n","[5, 149, 21, 37, 5, 202, 218, 9, 7, 498, 15, 18, 134, 96, 9, 5618, 4, 9, 107, 6450, 15, 3, 32, 134, 207, 187, 4, 12, 134, 623, 23, 49, 15, 142, 47, 369, 203, 390, 15]\n","0\n","\n","print AFTER shuffling and categorizing the label values\n","[16, 457, 12, 1, 8150, 5609, 5, 8, 3811, 7, 6050, 1, 259, 59, 13, 2, 80, 6557, 1, 6, 44, 100, 1270, 493, 1861, 5, 8, 2275, 7, 25, 1, 205, 1299, 7, 323, 1, 1, 8, 1409, 4, 100, 1771, 10, 16, 420, 11, 9925, 85, 2340, 9925, 11, 3, 2275, 130, 283, 5, 1228, 7, 1, 69, 7, 196, 40, 14, 16, 6880, 4, 2146, 28, 147, 24, 13, 3, 161, 5649, 2275, 11, 3, 1, 30, 5, 8, 928, 59, 7, 21, 1, 11, 8113, 5, 406, 150, 66, 8, 44, 1337, 4, 1503, 7, 1465, 3, 205, 80, 1512, 3, 9925, 59, 23]\n","Label before categorizing:  1\n","0.0 1.0 0.0\n","[475, 66, 12, 6, 35, 2444, 42, 618, 5, 8, 13, 3, 1044, 10, 531, 60, 608, 52, 66, 8, 445, 1755, 1, 4, 41, 633, 62, 321, 11, 9, 52, 343, 7, 452, 6, 51, 53, 318]\n","Label before categorizing:  1\n","0.0 1.0 0.0\n","\n","printing shape of train data\n","(25000,) (25000, 3)\n","\n","printing after padding sequences\n","1008\n","(25000, 1008)\n","(25000, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bpis7KK-xWt_","colab_type":"text"},"source":["## Data iterator"]},{"cell_type":"code","metadata":{"id":"HplqDYrpxa94","colab_type":"code","colab":{}},"source":["class Dataiterator():\n","    '''\n","      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n","      2) Access to the entire dataset using all()\n","    '''\n","    \n","    def __init__(self, X, y, seq_length=32, decoder_dim=300, batch_size=32):      \n","        self.X = X \n","        self.y = y \n","        self.num_data = len(X) # total number of examples\n","        self.batch_size = batch_size # batch size\n","        self.reset() # initial: shuffling examples and set index to 0\n","    \n","    def __iter__(self): # iterates data\n","        return self\n","\n","\n","    def reset(self): # initials\n","        self.idx = 0\n","        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n","        \n","    def __next__(self): # return model inputs - outputs per batch\n","        X_ids = [] # hold ids per batch \n","        while len(X_ids) < self.batch_size:\n","            X_id = self.order[self.idx] # copy random id from initial shuffling\n","            X_ids.append(X_id)\n","            self.idx += 1 # \n","            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n","                self.reset()\n","                raise StopIteration()\n","        batch_X = self.X[np.array(X_ids)] # X values (encoder input) per batch\n","        batch_y = self.y[np.array(X_ids)] # y_in values (decoder input) per batch\n","        return batch_X, batch_y\n","\n","          \n","    def all(self): # return all data examples\n","        return self.X, self.y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J_psuvv2xvM6","colab_type":"text"},"source":["### LSTM Model for document level sentiment classification"]},{"cell_type":"code","metadata":{"id":"s-_nng_8xnhs","colab_type":"code","colab":{}},"source":["from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Input, Bidirectional\n","from keras.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSbGOVx6x08D","colab_type":"text"},"source":["### Input layer"]},{"cell_type":"code","metadata":{"id":"JttmdnFjx3GV","colab_type":"code","colab":{}},"source":["### YOUR CODE HERE\n","sentence_input = Input(shape=(None,), dtype='int32', name='sentence_input')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hvIvP0ZMx6Cx","colab_type":"text"},"source":["### Layer to train embedding weights of words"]},{"cell_type":"code","metadata":{"id":"YFH9SFMbx9Yh","colab_type":"code","outputId":"c44f2754-2e2d-489e-e48a-1b81e639aac6","executionInfo":{"status":"ok","timestamp":1559116493904,"user_tz":-120,"elapsed":965,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["### YOUR CODE HERE\n","vocab_size = len(words_idx)\n","word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')\n","emb_output = word_emb(sentence_input)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N8pJyhYayDE2","colab_type":"text"},"source":["### RNN based layer"]},{"cell_type":"code","metadata":{"id":"GiD0BbgcyFMV","colab_type":"code","outputId":"93eede3d-8a98-466e-8bae-8aea67510783","executionInfo":{"status":"ok","timestamp":1559116502158,"user_tz":-120,"elapsed":1245,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["### YOUR CODE HERE\n","dropout= 0.5\n","recurrent_dropout = 0.1 \n","lstm_layer = LSTM(300, return_sequences=False, dropout=dropout, \\\n","              recurrent_dropout=recurrent_dropout, name='lstm')(emb_output)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PeWpdD2eyIjT","colab_type":"text"},"source":["### Prediction layer"]},{"cell_type":"code","metadata":{"id":"d6pQV-f2yKhV","colab_type":"code","colab":{}},"source":["### YOUR CODE HERE\n","densed = Dense(3, name='dense')(lstm_layer)\n","probs = Activation('softmax')(densed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"586nVjgiyOkV","colab_type":"text"},"source":["### Construct the model"]},{"cell_type":"code","metadata":{"id":"xfGdR9HjyROc","colab_type":"code","colab":{}},"source":["### YOUR CODE HERE\n","\n","model = Model(inputs=[sentence_input], outputs=probs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UKG5o4Y1yTMH","colab_type":"code","colab":{}},"source":["import keras.optimizers as opt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WtGxm9iRyVCA","colab_type":"code","outputId":"22696c02-328e-45a7-b751-66f00eb8edcd","executionInfo":{"status":"ok","timestamp":1559116513984,"user_tz":-120,"elapsed":1148,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n","model.summary()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sentence_input (InputLayer)  (None, None)              0         \n","_________________________________________________________________\n","word_emb (Embedding)         (None, None, 300)         3000900   \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 300)               721200    \n","_________________________________________________________________\n","dense (Dense)                (None, 3)                 903       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 3)                 0         \n","=================================================================\n","Total params: 3,723,003\n","Trainable params: 3,723,003\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OQvkoMZxyfae","colab_type":"text"},"source":["### Training with batch generator"]},{"cell_type":"code","metadata":{"id":"npXWemyLyj6M","colab_type":"code","colab":{}},"source":["batch_size = 32\n","train_steps_epoch = len(train_x_)/batch_size\n","batch_train_iter = Dataiterator(train_x_, train_y, batch_size)\n","val_steps_epoch = len(dev_x_)/batch_size\n","batch_val_iter = Dataiterator(dev_x_, dev_y, batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IgI3_oETysxS","colab_type":"code","colab":{}},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","def train_generator(model, batch_train_iter, batch_val_iter):\n","    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n","                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n","                                     monitor='val_loss', save_best_only=False, \\\n","                                     save_weights_only=True)\n","                     ]\n","    \n","    def train_gen():\n","        while True:\n","            train_batches = [[X, y] for X, y in batch_train_iter]\n","            for train_batch in train_batches:\n","                yield train_batch\n","                \n","    def val_gen():\n","        while True:\n","            val_batches = [[X, y] for X, y in batch_val_iter]\n","            for val_batch in val_batches:\n","                yield val_batch\n","                \n","    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n","                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n","                                  epochs = 20, callbacks = earlystop_callbacks)\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SZx9BcWy0fu","colab_type":"code","outputId":"5e68a3be-d839-4eef-a0b5-11a47c53d8a3","colab":{"base_uri":"https://localhost:8080/","height":591},"executionInfo":{"status":"ok","timestamp":1559061008637,"user_tz":-120,"elapsed":2580985,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}}},"source":["train_generator(model, batch_train_iter, batch_val_iter)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/20\n","782/781 [==============================] - 1505s 2s/step - loss: 0.8036 - categorical_accuracy: 0.6379 - val_loss: 0.6843 - val_categorical_accuracy: 0.7130\n","Epoch 2/20\n","782/781 [==============================] - 1486s 2s/step - loss: 0.6378 - categorical_accuracy: 0.7353 - val_loss: 0.6903 - val_categorical_accuracy: 0.7160\n","Epoch 3/20\n","782/781 [==============================] - 1481s 2s/step - loss: 0.5521 - categorical_accuracy: 0.7723 - val_loss: 0.6020 - val_categorical_accuracy: 0.7418\n","Epoch 4/20\n","782/781 [==============================] - 1492s 2s/step - loss: 0.4958 - categorical_accuracy: 0.7974 - val_loss: 0.5696 - val_categorical_accuracy: 0.7592\n","Epoch 5/20\n","782/781 [==============================] - 1488s 2s/step - loss: 0.4478 - categorical_accuracy: 0.8192 - val_loss: 0.5605 - val_categorical_accuracy: 0.7660\n","Epoch 6/20\n","782/781 [==============================] - 1481s 2s/step - loss: 0.4057 - categorical_accuracy: 0.8389 - val_loss: 0.5823 - val_categorical_accuracy: 0.7712\n","Epoch 7/20\n","782/781 [==============================] - 1476s 2s/step - loss: 0.3646 - categorical_accuracy: 0.8578 - val_loss: 0.5883 - val_categorical_accuracy: 0.7600\n","Epoch 8/20\n","782/781 [==============================] - 1480s 2s/step - loss: 0.3210 - categorical_accuracy: 0.8785 - val_loss: 0.6690 - val_categorical_accuracy: 0.7592\n","Epoch 9/20\n","782/781 [==============================] - 1472s 2s/step - loss: 0.2899 - categorical_accuracy: 0.8908 - val_loss: 0.6518 - val_categorical_accuracy: 0.7655\n","Epoch 10/20\n","782/781 [==============================] - 1469s 2s/step - loss: 0.2520 - categorical_accuracy: 0.9065 - val_loss: 0.7266 - val_categorical_accuracy: 0.7590\n","Epoch 11/20\n","782/781 [==============================] - 1449s 2s/step - loss: 0.2175 - categorical_accuracy: 0.9226 - val_loss: 0.7781 - val_categorical_accuracy: 0.7628\n","Epoch 12/20\n","782/781 [==============================] - 1446s 2s/step - loss: 0.1860 - categorical_accuracy: 0.9328 - val_loss: 0.8257 - val_categorical_accuracy: 0.7550\n","Epoch 13/20\n","782/781 [==============================] - 1444s 2s/step - loss: 0.1568 - categorical_accuracy: 0.9459 - val_loss: 0.9222 - val_categorical_accuracy: 0.7440\n","Epoch 14/20\n","782/781 [==============================] - 1442s 2s/step - loss: 0.1327 - categorical_accuracy: 0.9529 - val_loss: 0.9555 - val_categorical_accuracy: 0.7472\n","Epoch 15/20\n","782/781 [==============================] - 1439s 2s/step - loss: 0.1120 - categorical_accuracy: 0.9608 - val_loss: 1.0676 - val_categorical_accuracy: 0.7400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4D7HRj6VV8Dh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"9e079f92-ebf6-4b83-d530-cb8d6e8bb12d","executionInfo":{"status":"ok","timestamp":1559062587044,"user_tz":-120,"elapsed":16445,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}}},"source":["# start testing\n","# predictions = model.predict(test_x_, verbose = 0)\n","score,acc = model.evaluate(test_x_, test_y, verbose = 2, batch_size = 32)\n","print(\"score: %.2f\" % (score))\n","print(\"acc: %.2f\" % (acc))\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["score: 0.82\n","acc: 0.79\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GVSEDl7AsUAg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VeOxBf4XfJVQ","colab_type":"text"},"source":["### Bidirectional LSTM"]},{"cell_type":"code","metadata":{"id":"XGb-IW6bfKBP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":302},"outputId":"011ac16e-9f75-4928-9ddf-8d3918f488a1","executionInfo":{"status":"ok","timestamp":1559116539813,"user_tz":-120,"elapsed":2114,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}}},"source":["sentence_input = Input(shape=(None,), dtype='int32', name='sentence_input')\n","vocab_size = len(words_idx)\n","word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')\n","emb_output = word_emb(sentence_input)\n","\n","dropout= 0.5\n","recurrent_dropout = 0.1 \n","lstm_layer = Bidirectional(LSTM(300, return_sequences=False, dropout=dropout, recurrent_dropout=recurrent_dropout, name='bilstm'))(emb_output)\n","densed = Dense(3, name='dense')(lstm_layer)\n","probs = Activation('softmax')(densed)\n","biModel = Model(inputs=[sentence_input], outputs=probs)\n","optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)\n","biModel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n","biModel.summary()\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sentence_input (InputLayer)  (None, None)              0         \n","_________________________________________________________________\n","word_emb (Embedding)         (None, None, 300)         3000900   \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 600)               1442400   \n","_________________________________________________________________\n","dense (Dense)                (None, 3)                 1803      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 3)                 0         \n","=================================================================\n","Total params: 4,445,103\n","Trainable params: 4,445,103\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yJ_GCcoIYT_b","colab_type":"code","colab":{}},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","def train_generator(model, batch_train_iter, batch_val_iter):\n","    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n","                 ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n","                                 monitor='val_loss', save_best_only=False, \\\n","                                 save_weights_only=True)\n","                 ]\n","\n","    def train_gen():\n","        while True:\n","            train_batches = [[X, y] for X, y in batch_train_iter]\n","            for train_batch in train_batches:\n","                yield train_batch\n","\n","    def val_gen():\n","        while True:\n","          val_batches = [[X, y] for X, y in batch_val_iter]\n","          for val_batch in val_batches:\n","              yield val_batch\n","\n","    bidirecthistory = biModel.fit_generator(train_gen(), validation_data=val_gen(), \\\n","                              validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n","                              epochs = 20, callbacks = earlystop_callbacks)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"58ub2Dc9aRB8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":162},"outputId":"02e6f6c6-e4ed-4656-de19-f0cbc67acc59","executionInfo":{"status":"error","timestamp":1559160858264,"user_tz":-120,"elapsed":1582,"user":{"displayName":"Upasana Biswas","photoUrl":"https://lh6.googleusercontent.com/-v_JP6nlPeLU/AAAAAAAAAAI/AAAAAAAABBM/FlzoIRKVWwA/s64/photo.jpg","userId":"15447145155754903867"}}},"source":["train_generator(biModel, batch_train_iter, batch_val_iter)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-46209c1a33c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_train_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_val_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"]}]},{"cell_type":"code","metadata":{"id":"suKwrCmrzWkQ","colab_type":"code","colab":{}},"source":["# # unidirectional LSTM model\n","# # input length  = num of time steps\n","# hidden_size = 64\n","# lstm_out = 3\n","# batch_size = 10000 #vocabulary\n","\n","# model = Sequential()\n","# model.add(Embedding(batch_size, hidden_size, input_length = train_x_.shape[1]))\n","# model.add(LSTM(hidden_size, return_sequences = True))\n","# model.add(SpatialDropout1D(0.4))\n","# model.add(LSTM(lstm_out, dropout_U = 0.2, dropout_W = 0.2))\n","# model.add(Dense(3,activation='sigmoid'))\n","# model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n","# print(model.summary())"],"execution_count":0,"outputs":[]}]}